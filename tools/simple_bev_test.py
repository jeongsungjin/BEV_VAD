#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ BEV ë°ì´í„°ì…‹ ë™ì‘ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import pickle
import json
import numpy as np
from PIL import Image
import cv2
import sys


def test_dummy_data_loading(data_root):
    """ë”ë¯¸ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("=== ë”ë¯¸ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ===")
    
    # 1. ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸
    train_file = os.path.join(data_root, 'vad_nuscenes_infos_train.pkl')
    val_file = os.path.join(data_root, 'vad_nuscenes_infos_val.pkl')
    map_file = os.path.join(data_root, 'nuscenes_map_anns_val.json')
    
    if not os.path.exists(train_file):
        print(f"âŒ í•™ìŠµ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {train_file}")
        return False
    
    if not os.path.exists(val_file):
        print(f"âŒ ê²€ì¦ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {val_file}")
        return False
    
    if not os.path.exists(map_file):
        print(f"âŒ ë§µ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {map_file}")
        return False
    
    print("âœ… ëª¨ë“  í•„ìš”í•œ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤")
    
    # 2. ë°ì´í„° ë¡œë“œ
    try:
        with open(train_file, 'rb') as f:
            train_data = pickle.load(f)
        print(f"âœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(train_data)} samples")
        
        with open(val_file, 'rb') as f:
            val_data = pickle.load(f)
        print(f"âœ… ê²€ì¦ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(val_data)} samples")
        
        with open(map_file, 'r') as f:
            map_data = json.load(f)
        print(f"âœ… ë§µ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(map_data['GTs'])} GT entries")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return False
    
    # 3. ë°ì´í„° êµ¬ì¡° í™•ì¸
    if train_data:
        sample = train_data[0]
        print(f"âœ… ìƒ˜í”Œ êµ¬ì¡° í™•ì¸:")
        print(f"  - í‚¤: {list(sample.keys())}")
        print(f"  - í† í°: {sample['token']}")
        print(f"  - GT ë°•ìŠ¤ ìˆ˜: {len(sample['gt_boxes'])}")
        print(f"  - GT ë¼ë²¨ ìˆ˜: {len(sample['gt_labels'])}")
        print(f"  - ë§µ ë¼ì¸ ìˆ˜: {len(sample['map_gt_lines'])}")
        
        # BEV ì´ë¯¸ì§€ í™•ì¸
        bev_image_path = os.path.join(data_root, 'bev_images', 'train', f"{sample['token']}.png")
        if os.path.exists(bev_image_path):
            print(f"âœ… BEV ì´ë¯¸ì§€ í™•ì¸: {bev_image_path}")
            
            # ì´ë¯¸ì§€ ë¡œë“œ í…ŒìŠ¤íŠ¸
            try:
                img = cv2.imread(bev_image_path)
                if img is not None:
                    print(f"âœ… BEV ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ: {img.shape}")
                else:
                    print("âŒ BEV ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
                    return False
            except Exception as e:
                print(f"âŒ BEV ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                return False
        else:
            print(f"âŒ BEV ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {bev_image_path}")
            return False
    
    return True


def test_bev_image_processing(data_root):
    """BEV ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\n=== BEV ì´ë¯¸ì§€ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    
    # í•™ìŠµ ë°ì´í„° ë¡œë“œ
    train_file = os.path.join(data_root, 'vad_nuscenes_infos_train.pkl')
    with open(train_file, 'rb') as f:
        train_data = pickle.load(f)
    
    if not train_data:
        print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    sample = train_data[0]
    bev_image_path = os.path.join(data_root, 'bev_images', 'train', f"{sample['token']}.png")
    
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(bev_image_path)
        print(f"âœ… ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ: {img.shape}")
        
        # RGB ë³€í™˜
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        print(f"âœ… RGB ë³€í™˜ ì„±ê³µ: {img_rgb.shape}")
        
        # í¬ê¸° ì¡°ì •
        target_size = (200, 200)
        img_resized = cv2.resize(img_rgb, target_size)
        print(f"âœ… í¬ê¸° ì¡°ì • ì„±ê³µ: {img_resized.shape}")
        
        # ì •ê·œí™”
        img_normalized = img_resized.astype(np.float32) / 255.0
        print(f"âœ… ì •ê·œí™” ì„±ê³µ: {img_normalized.shape}, dtype: {img_normalized.dtype}")
        
        # ì°¨ì› ë³€í™˜ (HWC -> CHW)
        img_chw = img_normalized.transpose(2, 0, 1)
        print(f"âœ… ì°¨ì› ë³€í™˜ ì„±ê³µ: {img_chw.shape}")
        
        # í†µê³„ í™•ì¸
        print(f"âœ… í”½ì…€ ê°’ ë²”ìœ„: [{img_chw.min():.3f}, {img_chw.max():.3f}]")
        print(f"âœ… í‰ê· ê°’: {img_chw.mean():.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return False


def test_gt_data_processing(data_root):
    """GT ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\n=== GT ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    
    # í•™ìŠµ ë°ì´í„° ë¡œë“œ
    train_file = os.path.join(data_root, 'vad_nuscenes_infos_train.pkl')
    with open(train_file, 'rb') as f:
        train_data = pickle.load(f)
    
    if not train_data:
        print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    sample = train_data[0]
    
    try:
        # GT ë°•ìŠ¤ ì²˜ë¦¬
        gt_boxes = np.array(sample['gt_boxes'])
        print(f"âœ… GT ë°•ìŠ¤ ì²˜ë¦¬: {gt_boxes.shape}")
        print(f"  - ë°•ìŠ¤ í˜•íƒœ: {gt_boxes.dtype}")
        print(f"  - ë°•ìŠ¤ ê°œìˆ˜: {len(gt_boxes)}")
        
        # GT ë¼ë²¨ ì²˜ë¦¬
        gt_labels = np.array(sample['gt_labels'])
        print(f"âœ… GT ë¼ë²¨ ì²˜ë¦¬: {gt_labels.shape}")
        print(f"  - ë¼ë²¨ ê°œìˆ˜: {len(gt_labels)}")
        print(f"  - ë¼ë²¨ ë²”ìœ„: [{gt_labels.min()}, {gt_labels.max()}]")
        
        # ë§µ ë°ì´í„° ì²˜ë¦¬
        map_lines = sample['map_gt_lines']
        map_labels = np.array(sample['map_gt_labels'])
        print(f"âœ… ë§µ ë°ì´í„° ì²˜ë¦¬:")
        print(f"  - ë§µ ë¼ì¸ ìˆ˜: {len(map_lines)}")
        print(f"  - ë§µ ë¼ë²¨ ìˆ˜: {len(map_labels)}")
        
        # ì²« ë²ˆì§¸ ë¼ì¸ í™•ì¸
        if map_lines:
            first_line = map_lines[0]
            print(f"  - ì²« ë²ˆì§¸ ë¼ì¸ í¬ì¸íŠ¸ ìˆ˜: {len(first_line)//2}")
            print(f"  - ì²« ë²ˆì§¸ ë¼ì¸ ë°ì´í„° íƒ€ì…: {type(first_line[0])}")
        
        return True
        
    except Exception as e:
        print(f"âŒ GT ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return False


def test_data_consistency(data_root):
    """ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
    print("\n=== ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # í•™ìŠµ ë°ì´í„° ë¡œë“œ
        train_file = os.path.join(data_root, 'vad_nuscenes_infos_train.pkl')
        with open(train_file, 'rb') as f:
            train_data = pickle.load(f)
        
        # ë§µ ë°ì´í„° ë¡œë“œ
        map_file = os.path.join(data_root, 'nuscenes_map_anns_val.json')
        with open(map_file, 'r') as f:
            map_data = json.load(f)
        
        # ì¼ê´€ì„± í™•ì¸
        print(f"âœ… í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(train_data)}")
        print(f"âœ… ë§µ GT ìˆ˜: {len(map_data['GTs'])}")
        
        # í† í° ì¼ì¹˜ í™•ì¸
        train_tokens = set(sample['token'] for sample in train_data)
        map_tokens = set(map_data['GTs'].keys())
        
        common_tokens = train_tokens & map_tokens
        print(f"âœ… ê³µí†µ í† í° ìˆ˜: {len(common_tokens)}")
        
        if len(common_tokens) == len(train_tokens):
            print("âœ… ëª¨ë“  í•™ìŠµ ìƒ˜í”Œì— ë§µ GTê°€ ìˆìŠµë‹ˆë‹¤")
        else:
            print(f"âš ï¸  ì¼ë¶€ ìƒ˜í”Œì— ë§µ GTê°€ ì—†ìŠµë‹ˆë‹¤: {len(train_tokens) - len(common_tokens)}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì¼ì¹˜ í™•ì¸
        missing_images = 0
        for sample in train_data:
            bev_image_path = os.path.join(data_root, 'bev_images', 'train', f"{sample['token']}.png")
            if not os.path.exists(bev_image_path):
                missing_images += 1
        
        if missing_images == 0:
            print("âœ… ëª¨ë“  ìƒ˜í”Œì— BEV ì´ë¯¸ì§€ê°€ ìˆìŠµë‹ˆë‹¤")
        else:
            print(f"âŒ {missing_images}ê°œ ìƒ˜í”Œì— BEV ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        return missing_images == 0
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ê°„ë‹¨í•œ BEV ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--data-root', default='data/nuscenes_dummy',
                       help='ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ ê°„ë‹¨í•œ BEV ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ë°ì´í„° ê²½ë¡œ: {args.data_root}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        ("ë”ë¯¸ ë°ì´í„° ë¡œë”©", test_dummy_data_loading),
        ("BEV ì´ë¯¸ì§€ ì²˜ë¦¬", test_bev_image_processing),
        ("GT ë°ì´í„° ì²˜ë¦¬", test_gt_data_processing),
        ("ë°ì´í„° ì¼ê´€ì„±", test_data_consistency),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func(args.data_root)
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            results.append((test_name, False))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*50)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*50)
    
    for test_name, success in results:
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        print(f"{test_name}: {status}")
    
    all_success = all(success for _, success in results)
    
    if all_success:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ë”ë¯¸ ë°ì´í„°ì…‹ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ë‹¨ê³„:")
        print("1. mmdet3d í™˜ê²½ ì„¤ì • ì™„ë£Œ")
        print("2. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
        print("3. ì‹¤ì œ í•™ìŠµ ì‹œì‘")
    else:
        print("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë°ì´í„° ìƒì„±ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == '__main__':
    main() 